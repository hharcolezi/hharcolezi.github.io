---
permalink: /projects/
title: "Projects"
excerpt: "Research Projects"
author_profile: true
redirect_from:
  - /projects.html
---

{% include base_path %}

## Current Projects

- **Responsible AI: Design, Regulation, and Conformity [(RAIDAC+)](https://miai-cluster.univ-grenoble-alpes.fr/research/chairs/raidac-responsible-ai-design-regulation-and-conformity--1644435.kjsp)** (**2025 – 2029**)  
  *Funding:* 500,000€ — [MIAI Cluster Chair](https://miai-cluster.univ-grenoble-alpes.fr/english/)  
  *Role:* Co-Chair (with Prof. [Theodore Christakis](https://cesice.univ-grenoble-alpes.fr/centre/membres/theodore-christakis))  
  *Scope:* Building accountable and compliant AI systems by bridging legal, regulatory, and technical dimensions of Responsible AI.

- **Aligning Privacy, Utility, and Fairness for Responsible AI [(AI-PULSE)](https://project.inria.fr/aipulse/)** (**2025 – 2029**)  
  *Funding:* 347,310€ — [ANR JCJC (Young Researcher)](https://anr.fr/fr/detail/call/aapg-appel-a-projets-generique-2024/)  
  *Role:* Principal Investigator  
  *Scope:* Studying fundamental trade-offs between privacy, fairness, and machine learning performance; designing new methods to enforce all three simultaneously.

- **Algorithmic Auditing of Privacy and Fairness [(AUDIT-PAIR)](https://team.inria.fr/auditpair/)** (**2024 – 2026**)  
  *Funding:* 32,000€ — Inria Associated Team  
  *Role:* Principal Investigator (Inria side)  
  *Partners:* Inria Privatics, UQAM, ÉTS Montréal  
  *Scope:* Cross-continent collaboration on tools and methods for auditing AI systems under privacy and fairness constraints.

---

## Past Projects

- **Exploring the Interplay of Differential Privacy and Fairness in ML** (**2024 – 2025**)  
  *Funding:* 10,000€ — [MIAI Open Call](https://miai-cluster.univ-grenoble-alpes.fr/research/projects-for-the-development-and-promotion-of-ai/)  
  *Role:* Principal Investigator  
  *Scope:* Empirical and theoretical analysis of fairness–privacy interaction in real-world ML scenarios.
